{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# MLX\n",
    "import mlx.core as mx\n",
    "import mlx.nn as mnn\n",
    "import mlx.optimizers as moptim\n",
    "from functools import partial\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Benchmark knobs\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 256\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 5e-4\n",
    "\n",
    "NUM_WORKERS = 2  # only used if you decide to use DataLoader (we won't, for fairness)\n",
    "PRINT_EVERY = 200  # batches\n",
    "\n",
    "# CIFAR-10 normalization (common)\n",
    "CIFAR_MEAN = np.array([0.4914, 0.4822, 0.4465], dtype=np.float32)\n",
    "CIFAR_STD  = np.array([0.2470, 0.2435, 0.2616], dtype=np.float32)\n",
    "\n",
    "def now():\n",
    "    return time.perf_counter()\n",
    "\n",
    "def torch_sync(device: str):\n",
    "    # For accurate timing; MPS is async.\n",
    "    if device == \"mps\":\n",
    "        torch.mps.synchronize()\n",
    "\n",
    "def mlx_sync(*arrays):\n",
    "    # MLX is lazy; force compute.\n",
    "    mx.eval(*arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimir/apple-silicon-toolkit/.venv/lib/python3.12/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  entry = pickle.load(f, encoding=\"latin1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (50000, 3, 32, 32) (50000,) | Test: (10000, 3, 32, 32) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Download once using torchvision, then store as uint8 in RAM.\n",
    "train_set = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True)\n",
    "test_set  = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True)\n",
    "\n",
    "def dataset_to_numpy(ds):\n",
    "    # ds.data is uint8 [N,H,W,C] already for CIFAR10 in torchvision\n",
    "    x = ds.data  # uint8 NHWC\n",
    "    y = np.array(ds.targets, dtype=np.int64)\n",
    "    return x, y\n",
    "\n",
    "x_train_nhwc_u8, y_train = dataset_to_numpy(train_set)\n",
    "x_test_nhwc_u8,  y_test  = dataset_to_numpy(test_set)\n",
    "\n",
    "# Torch wants NCHW float32\n",
    "x_train_nchw = np.transpose(x_train_nhwc_u8, (0,3,1,2)).astype(np.float32)\n",
    "x_test_nchw  = np.transpose(x_test_nhwc_u8,  (0,3,1,2)).astype(np.float32)\n",
    "\n",
    "# MLX wants NHWC float32\n",
    "x_train_nhwc = x_train_nhwc_u8.astype(np.float32)\n",
    "x_test_nhwc  = x_test_nhwc_u8.astype(np.float32)\n",
    "\n",
    "print(\"Train:\", x_train_nchw.shape, y_train.shape, \"| Test:\", x_test_nchw.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches_indices(n, batch_size, shuffle=True, seed=SEED):\n",
    "    idx = np.arange(n)\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        rng.shuffle(idx)\n",
    "    # drop_last\n",
    "    n_full = (n // batch_size) * batch_size\n",
    "    idx = idx[:n_full]\n",
    "    return idx.reshape(-1, batch_size)\n",
    "\n",
    "def iter_torch_batches(x_nchw_f32, y_i64, batch_size, device, shuffle=True, seed=SEED):\n",
    "    batches = make_batches_indices(len(y_i64), batch_size, shuffle=shuffle, seed=seed)\n",
    "    mean = torch.tensor(CIFAR_MEAN.reshape(1,3,1,1), device=device)\n",
    "    std  = torch.tensor(CIFAR_STD.reshape(1,3,1,1), device=device)\n",
    "\n",
    "    for bi, b in enumerate(batches):\n",
    "        xb = torch.from_numpy(x_nchw_f32[b]).to(device=device)\n",
    "        yb = torch.from_numpy(y_i64[b]).to(device=device)\n",
    "\n",
    "        # Normalize on-device\n",
    "        xb = (xb / 255.0 - mean) / std\n",
    "        yield bi, xb, yb\n",
    "\n",
    "def iter_mlx_batches(x_nhwc_f32, y_i64, batch_size, shuffle=True, seed=SEED):\n",
    "    batches = make_batches_indices(len(y_i64), batch_size, shuffle=shuffle, seed=seed)\n",
    "    mean = mx.array(CIFAR_MEAN.reshape(1,1,1,3))\n",
    "    std  = mx.array(CIFAR_STD.reshape(1,1,1,3))\n",
    "\n",
    "    for bi, b in enumerate(batches):\n",
    "        xb = mx.array(x_nhwc_f32[b])\n",
    "        yb = mx.array(y_i64[b])\n",
    "        xb = (xb / 255.0 - mean) / std\n",
    "        yield bi, xb, yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "def build_torch_resnet18_cifar(num_classes=10):\n",
    "    model = resnet18(num_classes=num_classes)\n",
    "    # CIFAR stem: 3x3 conv, stride 1, no maxpool\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlxBasicBlock(mnn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_ch, out_ch, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = mnn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1   = mnn.BatchNorm(out_ch)\n",
    "        self.conv2 = mnn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2   = mnn.BatchNorm(out_ch)\n",
    "\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.down = mnn.Sequential(\n",
    "                mnn.Conv2d(in_ch, out_ch, kernel_size=1, stride=stride, padding=0, bias=False),\n",
    "                mnn.BatchNorm(out_ch),\n",
    "            )\n",
    "        else:\n",
    "            self.down = None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = mnn.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.down is not None:\n",
    "            identity = self.down(identity)\n",
    "\n",
    "        out = out + identity\n",
    "        out = mnn.relu(out)\n",
    "        return out\n",
    "\n",
    "class MlxResNet(mnn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        # CIFAR stem (NHWC)\n",
    "        self.conv1 = mnn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1   = mnn.BatchNorm(64)\n",
    "\n",
    "        self.in_ch = 64\n",
    "        self.layer1 = self._make_layer(64,  2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "\n",
    "        self.fc = mnn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, out_ch, blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(MlxBasicBlock(self.in_ch, out_ch, stride=stride))\n",
    "        self.in_ch = out_ch\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(MlxBasicBlock(self.in_ch, out_ch, stride=1))\n",
    "        return mnn.Sequential(*layers)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = mnn.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        # Global average pool over H,W (NHWC)\n",
    "        x = mx.mean(x, axis=(1,2))  # -> (N, C)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## benchmark helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_torch_train(name: str, device: str, use_compile: bool):\n",
    "    assert device in (\"cpu\", \"mps\")\n",
    "    if device == \"mps\" and not torch.backends.mps.is_available():\n",
    "        return {\"name\": name, \"status\": \"SKIP (no MPS)\", \"device\": device}\n",
    "\n",
    "    torch_device = torch.device(device)\n",
    "    model = build_torch_resnet18_cifar().to(torch_device)\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    # torch.compile (default backend is \"inductor\")  [oai_citation:4‡PyTorch Documentation](https://docs.pytorch.org/docs/stable/generated/torch.compile.html?utm_source=chatgpt.com)\n",
    "    if use_compile:\n",
    "        try:\n",
    "            model = torch.compile(model)\n",
    "        except Exception as e:\n",
    "            return {\"name\": name, \"status\": f\"FAIL compile: {type(e).__name__}: {e}\", \"device\": device}\n",
    "\n",
    "    # Warm-up single step (important esp. for compile + async backends)\n",
    "    model.train()\n",
    "    bi, xb, yb = next(iter_torch_batches(x_train_nchw, y_train, BATCH_SIZE, device, shuffle=True, seed=SEED))\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "    out = model(xb)\n",
    "    loss = F.cross_entropy(out, yb)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    torch_sync(device)\n",
    "\n",
    "    epoch_times = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        t0 = now()\n",
    "        model.train()\n",
    "\n",
    "        for bi, xb, yb in iter_torch_batches(x_train_nchw, y_train, BATCH_SIZE, device, shuffle=True, seed=SEED+epoch+1):\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            out = model(xb)\n",
    "            loss = F.cross_entropy(out, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        torch_sync(device)\n",
    "        t1 = now()\n",
    "        epoch_times.append(t1 - t0)\n",
    "        print(f\"[{name}] epoch {epoch+1}/{EPOCHS} time: {epoch_times[-1]:.3f}s\")\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"status\": \"OK\",\n",
    "        \"device\": device,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"epoch_time_mean_s\": float(np.mean(epoch_times)),\n",
    "        \"epoch_time_std_s\": float(np.std(epoch_times)),\n",
    "        \"total_time_s\": float(np.sum(epoch_times)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mlx_train(name: str, use_compile: bool):\n",
    "    model = MlxResNet(num_classes=10)\n",
    "    optimizer = moptim.SGD(learning_rate=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    def loss_fn(model, x, y):\n",
    "        logits = model(x)\n",
    "        return mnn.losses.cross_entropy(logits, y)\n",
    "\n",
    "    # Uncompiled step\n",
    "    loss_and_grad = mnn.value_and_grad(model, loss_fn)\n",
    "\n",
    "    def step_eager(x, y):\n",
    "        loss, grads = loss_and_grad(model, x, y)\n",
    "        optimizer.update(model, grads)\n",
    "        return loss\n",
    "\n",
    "    # Compiled step (capture state in+out)  [oai_citation:5‡ml-explore.github.io](https://ml-explore.github.io/mlx/build/html/usage/compile.html)\n",
    "    state = [model.state, optimizer.state, mx.random.state]\n",
    "\n",
    "    @partial(mx.compile, inputs=state, outputs=state)\n",
    "    def step_compiled(x, y):\n",
    "        loss_and_grad_fn = mnn.value_and_grad(model, loss_fn)\n",
    "        loss, grads = loss_and_grad_fn(model, x, y)\n",
    "        optimizer.update(model, grads)\n",
    "        return loss\n",
    "\n",
    "    step = step_compiled if use_compile else step_eager\n",
    "\n",
    "    # Warm-up one step\n",
    "    bi, xb, yb = next(iter_mlx_batches(x_train_nhwc, y_train, BATCH_SIZE, shuffle=True, seed=SEED))\n",
    "    loss = step(xb, yb)\n",
    "    mlx_sync(state)\n",
    "\n",
    "    epoch_times = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        t0 = now()\n",
    "        for bi, xb, yb in iter_mlx_batches(x_train_nhwc, y_train, BATCH_SIZE, shuffle=True, seed=SEED+epoch+1):\n",
    "            loss = step(xb, yb)\n",
    "            # Force compute so timing is real\n",
    "            mlx_sync(state)\n",
    "\n",
    "        t1 = now()\n",
    "        epoch_times.append(t1 - t0)\n",
    "        print(f\"[{name}] epoch {epoch+1}/{EPOCHS} time: {epoch_times[-1]:.3f}s\")\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"status\": \"OK\",\n",
    "        \"device\": \"mlx\",\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"epoch_time_mean_s\": float(np.mean(epoch_times)),\n",
    "        \"epoch_time_std_s\": float(np.std(epoch_times)),\n",
    "        \"total_time_s\": float(np.sum(epoch_times)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch_cpu_baseline] epoch 1/10 time: 974.931s\n",
      "[torch_cpu_baseline] epoch 2/10 time: 1006.732s\n",
      "[torch_cpu_baseline] epoch 3/10 time: 1073.400s\n",
      "[torch_cpu_baseline] epoch 4/10 time: 1052.026s\n",
      "[torch_cpu_baseline] epoch 5/10 time: 1069.065s\n",
      "[torch_cpu_baseline] epoch 6/10 time: 1050.840s\n",
      "[torch_cpu_baseline] epoch 7/10 time: 1063.588s\n",
      "[torch_cpu_baseline] epoch 8/10 time: 977.699s\n",
      "[torch_cpu_baseline] epoch 9/10 time: 1040.370s\n",
      "[torch_cpu_baseline] epoch 10/10 time: 1065.361s\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "results.append(run_torch_train(\"torch_cpu_baseline\", device=\"cpu\", use_compile=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(run_torch_train(\"torch_cpu_compile\", device=\"cpu\", use_compile=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch_mps] epoch 1/10 time: 142.176s\n",
      "[torch_mps] epoch 2/10 time: 144.068s\n",
      "[torch_mps] epoch 3/10 time: 145.051s\n",
      "[torch_mps] epoch 4/10 time: 150.447s\n",
      "[torch_mps] epoch 5/10 time: 163.132s\n",
      "[torch_mps] epoch 6/10 time: 183.788s\n",
      "[torch_mps] epoch 7/10 time: 207.818s\n",
      "[torch_mps] epoch 8/10 time: 204.126s\n",
      "[torch_mps] epoch 9/10 time: 199.734s\n",
      "[torch_mps] epoch 10/10 time: 157.943s\n"
     ]
    }
   ],
   "source": [
    "results.append(run_torch_train(\"torch_mps\", device=\"mps\", use_compile=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(run_torch_train(\"torch_mps_compile\", device=\"mps\", use_compile=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(run_mlx_train(\"mlx\", use_compile=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(run_mlx_train(\"mlx_compile\", use_compile=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Keep rows that have timing\n",
    "timed = df[df[\"status\"].eq(\"OK\")].copy()\n",
    "timed = timed.sort_values(\"epoch_time_mean_s\", ascending=True)\n",
    "\n",
    "print(\"=== Raw results ===\")\n",
    "display(df)\n",
    "\n",
    "print(\"\\n=== Ranking (fastest mean epoch time first) ===\")\n",
    "display(timed[[\"name\",\"device\",\"epoch_time_mean_s\",\"epoch_time_std_s\",\"total_time_s\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
